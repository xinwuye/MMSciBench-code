# MMSciBench

![License](https://img.shields.io/github/license/xinwuye/MMSciBench-code)
![Stars](https://img.shields.io/github/stars/xinwuye/MMSciBench-code?style=social)
![Issues](https://img.shields.io/github/issues/xinwuye/MMSciBench-code)

## ğŸ“Œ Overview

**MMSciBench** focuses on mathematics and physics that evaluates scientific reasoning capabilities. This repository contains the code for the benchmark. The dataset is available on Hugging Face: [MMSciBench Dataset](https://huggingface.co/datasets/XinwuYe/MMSciBench).

## ğŸ“– Paper
If you use this benchmark in your research, please cite our paper:

```
@article{}
```

## ğŸ›  Installation

Clone the repository:

```bash
git clone https://github.com/xinwuye/MMSciBench-code.git
cd MMSciBench-code
```

## ğŸ“Š Benchmark Dataset
The dataset for MMSciBench is available on Hugging Face:

ğŸ”— [MMSciBench Dataset](https://huggingface.co/datasets/XinwuYe/MMSciBench)

## ğŸš€ Usage

### Running Evaluation
To evaluate models on the benchmark, use the following command:

```bash
python exp.py
python exp_hf.py
python eval1.py
```

## ğŸ“ˆ Results
Once evaluation is complete, results will be saved.

## ğŸ“œ License
This project is licensed under the [Apache-2.0 License](LICENSE).

## ğŸ¤ Contributing
We welcome contributions! To contribute:
1. Fork the repository.
2. Create a new branch: `git checkout -b feature-branch-name`.
3. Commit your changes: `git commit -m 'Add a new feature'`.
4. Push to the branch: `git push origin feature-branch-name`.
5. Open a pull request.

## ğŸ”— Acknowledgments
We thank the open-source community and previous works that inspired this benchmark.

## ğŸ“¬ Contact
For questions or collaborations, please open an issue.
